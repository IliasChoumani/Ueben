{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Website Scrapen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline: Komodo dragon\n",
      "Binomial Name: Varanus komodoensis\n",
      "Class: Reptilia\n",
      "Order: Squamata\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "\n",
    "# URL der Wikipedia-Seite\n",
    "url = \"https://en.wikipedia.org/wiki/Komodo_dragon\"\n",
    "\n",
    "# HTTP-Anfrage an die URL senden\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# BeautifulSoup verwendet lxml als Parser\n",
    "tree = html.fromstring(response.content)\n",
    "\n",
    "# Überschrift der Wikipedia-Seite extrahieren\n",
    "headline = soup.find('h1', {'id': 'firstHeading'}).text\n",
    "\n",
    "# Funktion zum Extrahieren von Informationen anhand des XPaths\n",
    "def extract_info_xpath(xpath):\n",
    "    try:\n",
    "        return tree.xpath(xpath)[0].text_content().strip()\n",
    "    except IndexError:\n",
    "        return 'Nicht gefunden'\n",
    "\n",
    "# XPaths für die benötigten Informationen\n",
    "xpath_binomial_name = '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[18]/td/b/span/i'\n",
    "xpath_animal_class = '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[11]/td[2]/a'\n",
    "xpath_animal_order = '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[12]/td[2]/a'\n",
    "\n",
    "# Informationen extrahieren\n",
    "binomial_name = extract_info_xpath(xpath_binomial_name)\n",
    "animal_class = extract_info_xpath(xpath_animal_class)\n",
    "animal_order = extract_info_xpath(xpath_animal_order)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(f\"Headline: {headline}\")\n",
    "print(f\"Binomial Name: {binomial_name}\")\n",
    "print(f\"Class: {animal_class}\")\n",
    "print(f\"Order: {animal_order}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animal Number 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = \"https://en.wikipedia.org/wiki/Bald_eagle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code für beide Websiten (binominal name für bald eagle nicht gefunden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://en.wikipedia.org/wiki/Komodo_dragon\n",
      "Headline: Komodo dragon\n",
      "Binomial Name: Varanus komodoensis\n",
      "Class: Reptilia\n",
      "Order: Squamata\n",
      "----------------------------------------\n",
      "URL: https://en.wikipedia.org/wiki/Bald_eagle\n",
      "Headline: Bald eagle\n",
      "Binomial Name: Nicht gefunden\n",
      "Class: Animalia\n",
      "Order: Chordata\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "\n",
    "# URLs der Wikipedia-Seiten\n",
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Komodo_dragon\",\n",
    "    \"https://en.wikipedia.org/wiki/Bald_eagle\"\n",
    "]\n",
    "\n",
    "# XPaths für die benötigten Informationen\n",
    "xpaths = {\n",
    "    'binomial_name': '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[18]/td/b/span/i',\n",
    "    'animal_class': '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[11]/td[2]/a',\n",
    "    'animal_order': '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[12]/td[2]/a'\n",
    "}\n",
    "\n",
    "def extract_info_from_url(url, xpaths):\n",
    "    # HTTP-Anfrage an die URL senden\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    tree = html.fromstring(response.content)\n",
    "\n",
    "    # Überschrift der Wikipedia-Seite extrahieren\n",
    "    headline = soup.find('h1', {'id': 'firstHeading'}).text\n",
    "\n",
    "    # Funktion zum Extrahieren von Informationen anhand des XPaths\n",
    "    def extract_info_xpath(xpath):\n",
    "        try:\n",
    "            return tree.xpath(xpath)[0].text_content().strip()\n",
    "        except IndexError:\n",
    "            return 'Nicht gefunden'\n",
    "\n",
    "    # Informationen extrahieren\n",
    "    binomial_name = extract_info_xpath(xpaths['binomial_name'])\n",
    "    animal_class = extract_info_xpath(xpaths['animal_class'])\n",
    "    animal_order = extract_info_xpath(xpaths['animal_order'])\n",
    "\n",
    "    return {\n",
    "        'headline': headline,\n",
    "        'binomial_name': binomial_name,\n",
    "        'class': animal_class,\n",
    "        'order': animal_order\n",
    "    }\n",
    "\n",
    "# Ergebnisse für jede URL extrahieren und ausgeben\n",
    "for url in urls:\n",
    "    info = extract_info_from_url(url, xpaths)\n",
    "    print(f\"URL: {url}\")\n",
    "    print(f\"Headline: {info['headline']}\")\n",
    "    print(f\"Binomial Name: {info['binomial_name']}\")\n",
    "    print(f\"Class: {info['class']}\")\n",
    "    print(f\"Order: {info['order']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code für beide Websiten (funktioniert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://en.wikipedia.org/wiki/Komodo_dragon\n",
      "Headline: Komodo dragon\n",
      "Binomial Name: Varanus komodoensis\n",
      "Class: Reptilia\n",
      "Order: Squamata\n",
      "----------------------------------------\n",
      "URL: https://en.wikipedia.org/wiki/Bald_eagle\n",
      "Headline: Bald eagle\n",
      "Binomial Name: Haliaeetus leucocephalus\n",
      "Class: Accipitriformes\n",
      "Order: Aves\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "\n",
    "# URLs der Wikipedia-Seiten\n",
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Komodo_dragon\",\n",
    "    \"https://en.wikipedia.org/wiki/Bald_eagle\"\n",
    "]\n",
    "\n",
    "# XPaths für die benötigten Informationen, angepasst nach Tierart\n",
    "xpaths = {\n",
    "    \"Komodo_dragon\": {\n",
    "        'binomial_name': '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[18]/td/b/span/i',\n",
    "        'animal_class': '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[11]/td[2]/a',\n",
    "        'animal_order': '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[12]/td[2]/a'\n",
    "    },\n",
    "    \"Bald_eagle\": {\n",
    "        'binomial_name': '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[19]/td/b/span/i',\n",
    "        'animal_class': '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[14]/td[2]/a',\n",
    "        'animal_order': '/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table/tbody/tr[13]/td[2]/a'\n",
    "    }\n",
    "}\n",
    "\n",
    "def extract_info_from_url(url, xpaths):\n",
    "    # HTTP-Anfrage an die URL senden\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    tree = html.fromstring(response.content)\n",
    "\n",
    "    # Überschrift der Wikipedia-Seite extrahieren\n",
    "    headline = soup.find('h1', {'id': 'firstHeading'}).text\n",
    "\n",
    "    # Funktion zum Extrahieren von Informationen anhand des XPaths\n",
    "    def extract_info_xpath(xpath):\n",
    "        try:\n",
    "            return tree.xpath(xpath)[0].text_content().strip()\n",
    "        except IndexError:\n",
    "            return 'Nicht gefunden'\n",
    "\n",
    "    # Extrahieren des Titels aus der URL, um den passenden XPath zu wählen\n",
    "    title = url.split('/')[-1].replace('_', ' ')\n",
    "    if title == \"Komodo dragon\":\n",
    "        animal_xpaths = xpaths['Komodo_dragon']\n",
    "    elif title == \"Bald eagle\":\n",
    "        animal_xpaths = xpaths['Bald_eagle']\n",
    "    else:\n",
    "        animal_xpaths = {}\n",
    "    \n",
    "    # Informationen extrahieren\n",
    "    binomial_name = extract_info_xpath(animal_xpaths.get('binomial_name', ''))\n",
    "    animal_class = extract_info_xpath(animal_xpaths.get('animal_class', ''))\n",
    "    animal_order = extract_info_xpath(animal_xpaths.get('animal_order', ''))\n",
    "\n",
    "    return {\n",
    "        'headline': headline,\n",
    "        'binomial_name': binomial_name,\n",
    "        'class': animal_class,\n",
    "        'order': animal_order\n",
    "    }\n",
    "\n",
    "# Ergebnisse für jede URL extrahieren und ausgeben\n",
    "for url in urls:\n",
    "    info = extract_info_from_url(url, xpaths)\n",
    "    print(f\"URL: {url}\")\n",
    "    print(f\"Headline: {info['headline']}\")\n",
    "    print(f\"Binomial Name: {info['binomial_name']}\")\n",
    "    print(f\"Class: {info['class']}\")\n",
    "    print(f\"Order: {info['order']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
